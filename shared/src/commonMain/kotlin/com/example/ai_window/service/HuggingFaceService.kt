package com.example.ai_window.service

import com.example.ai_window.SERVER_PORT
import com.example.ai_window.model.*
import com.example.ai_window.util.getCurrentTimeMillis
import io.ktor.client.*
import io.ktor.client.call.*
import io.ktor.client.plugins.contentnegotiation.*
import io.ktor.client.request.*
import io.ktor.http.*
import io.ktor.serialization.kotlinx.json.*
import kotlinx.serialization.json.Json
import kotlin.Result

/**
 * –°–µ—Ä–≤–∏—Å –¥–ª—è –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è —Å HuggingFace Inference API —á–µ—Ä–µ–∑ –ø—Ä–æ–∫—Å–∏-—Å–µ—Ä–≤–µ—Ä
 */
class HuggingFaceService(
    private val hfToken: String,
    private val serverUrl: String = "http://localhost:$SERVER_PORT"
) {
    private val client = HttpClient {
        install(ContentNegotiation) {
            json(Json {
                ignoreUnknownKeys = true
                prettyPrint = true
                isLenient = true
            })
        }
    }

    /**
     * –û—Ç–ø—Ä–∞–≤–∏—Ç—å –∑–∞–ø—Ä–æ—Å –∫ –º–æ–¥–µ–ª–∏ —á–µ—Ä–µ–∑ –ø—Ä–æ–∫—Å–∏
     * –ò—Å–ø–æ–ª—å–∑—É–µ—Ç Chat Completion API (OpenAI-—Å–æ–≤–º–µ—Å—Ç–∏–º—ã–π —Ñ–æ—Ä–º–∞—Ç)
     */
    suspend fun generateText(
        modelId: String,
        prompt: String,
        maxTokens: Int = 500,
        temperature: Double = 0.7
    ): Result<HFDetailedResponse> {
        return try {
            val startTime = getCurrentTimeMillis()

            val request = HuggingFaceRequest(
                model = modelId,
                messages = listOf(
                    HFChatMessage(
                        role = "user",
                        content = prompt
                    )
                ),
                maxTokens = maxTokens,
                temperature = temperature,
                stream = false
            )

            println("üì§ HuggingFace REQUEST:")
            println("  Model: $modelId")
            println("  Prompt: ${prompt.take(100)}...")
            println("  Max tokens: $maxTokens")
            println("  Temperature: $temperature")

            val response: HuggingFaceResponse = client.post("$serverUrl/api/huggingface") {
                header("X-HF-Token", hfToken)
                contentType(ContentType.Application.Json)
                setBody(request)
            }.body()

            val endTime = getCurrentTimeMillis()
            val executionTime = endTime - startTime

            println("üì• HuggingFace RESPONSE:")
            println("  Execution time: ${executionTime}ms")
            println("  Model: ${response.model}")
            println("  Choices: ${response.choices?.size}")
            println("  Usage: ${response.usage}")
            println("  Error: ${response.error}")

            // –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ–¥–º–µ–Ω—ã –º–æ–¥–µ–ª–∏ (—Å –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–µ–π)
            val actualModel = response.model
            if (actualModel != null) {
                val normalizedRequested = normalizeModelName(modelId)
                val normalizedActual = normalizeModelName(actualModel)

                if (normalizedActual != normalizedRequested) {
                    println("‚ö†Ô∏è  WARNING: Model substitution detected!")
                    println("  Requested: $modelId (normalized: $normalizedRequested)")
                    println("  Actually used: $actualModel (normalized: $normalizedActual)")
                } else if (actualModel != modelId) {
                    println("‚ÑπÔ∏è  Model name normalized by provider:")
                    println("  Requested: $modelId")
                    println("  Returned: $actualModel")
                }
            }

            if (response.error != null) {
                return Result.failure(Exception("HuggingFace API error: ${response.error}"))
            }

            val generatedText = response.choices?.firstOrNull()?.message?.content
            if (generatedText == null) {
                return Result.failure(Exception("Empty response from HuggingFace API"))
            }

            // –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ä–µ–∞–ª—å–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏ —Ç–æ–∫–µ–Ω–æ–≤ –∏–∑ API
            val tokenUsage = response.usage ?: TokenUsage(
                promptTokens = 0,
                completionTokens = 0,
                totalTokens = 0
            )

            val detailedResponse = HFDetailedResponse(
                modelId = modelId,
                modelName = modelId.split("/").firstOrNull()?.split(":")?.firstOrNull() ?: modelId,
                generatedText = generatedText,
                executionTime = executionTime,
                tokenUsage = tokenUsage,
                actualModelUsed = actualModel  // –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∞–ª—å–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–Ω—É—é –º–æ–¥–µ–ª—å
            )

            Result.success(detailedResponse)
        } catch (e: Exception) {
            println("‚ùå HuggingFace Service error: ${e.message}")
            e.printStackTrace()
            Result.failure(e)
        }
    }

    /**
     * –ì–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –æ—Ç–≤–µ—Ç—ã –¥–ª—è –æ–¥–Ω–æ–≥–æ –ø—Ä–æ–º–ø—Ç–∞
     * (–¥–ª—è —Ä–∞—Å—á–µ—Ç–∞ –º–µ—Ç—Ä–∏–∫ —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏—è)
     */
    suspend fun generateMultiple(
        modelId: String,
        prompt: String,
        count: Int = 3,
        maxTokens: Int = 500,
        temperature: Double = 0.7,
        onProgress: (current: Int, total: Int) -> Unit = { _, _ -> }
    ): Result<List<HFDetailedResponse>> {
        val responses = mutableListOf<HFDetailedResponse>()

        for (i in 1..count) {
            onProgress(i, count)

            val result = generateText(
                modelId = modelId,
                prompt = prompt,
                maxTokens = maxTokens,
                temperature = temperature
            )

            when {
                result.isSuccess -> {
                    responses.add(result.getOrThrow())
                }
                result.isFailure -> {
                    return Result.failure(result.exceptionOrNull() ?: Exception("Unknown error"))
                }
            }
        }

        return Result.success(responses)
    }

    /**
     * –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –∏–º–µ–Ω–∏ –º–æ–¥–µ–ª–∏ –¥–ª—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–≥–æ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
     * - –£–±–∏—Ä–∞–µ—Ç —Å—É—Ñ—Ñ–∏–∫—Å—ã –ø—Ä–æ–≤–∞–π–¥–µ—Ä–æ–≤ (:fastest, :novita –∏ —Ç.–¥.)
     * - –ü—Ä–∏–≤–æ–¥–∏—Ç –∫ –Ω–∏–∂–Ω–µ–º—É —Ä–µ–≥–∏—Å—Ç—Ä—É
     */
    private fun normalizeModelName(modelName: String): String {
        return modelName
            .split(":")  // –£–±–∏—Ä–∞–µ–º —Å—É—Ñ—Ñ–∏–∫—Å –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞
            .first()
            .lowercase()  // –ü—Ä–∏–≤–æ–¥–∏–º –∫ –Ω–∏–∂–Ω–µ–º—É —Ä–µ–≥–∏—Å—Ç—Ä—É
            .trim()
    }

    fun close() {
        client.close()
    }
}
