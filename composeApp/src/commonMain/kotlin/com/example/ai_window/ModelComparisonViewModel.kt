package com.example.ai_window

import androidx.lifecycle.ViewModel
import androidx.lifecycle.viewModelScope
import com.example.ai_window.model.*
import com.example.ai_window.service.HuggingFaceService
import com.example.ai_window.service.ModelComparisonService
import kotlinx.coroutines.async
import kotlinx.coroutines.awaitAll
import kotlinx.coroutines.flow.MutableStateFlow
import kotlinx.coroutines.flow.StateFlow
import kotlinx.coroutines.flow.asStateFlow
import kotlinx.coroutines.launch

/**
 * –†–µ–∂–∏–º —Ä–∞–±–æ—Ç—ã —ç–∫—Ä–∞–Ω–∞ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
 */
enum class ComparisonMode {
    MODEL_COMPARISON,  // –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π
    TOKEN_ANALYSIS     // –ê–Ω–∞–ª–∏–∑ —Ç–æ–∫–µ–Ω–æ–≤
}

class ModelComparisonViewModel(
    hfToken: String
) : ViewModel() {

    private val hfService = HuggingFaceService(hfToken)
    private val comparisonService = ModelComparisonService(hfService)

    // –°–ø–∏—Å–æ–∫ –º–æ–¥–µ–ª–µ–π –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
    val models = HuggingFaceModels.AVAILABLE_MODELS

    // –†–µ–∂–∏–º —Ä–∞–±–æ—Ç—ã —ç–∫—Ä–∞–Ω–∞
    private val _comparisonMode = MutableStateFlow(ComparisonMode.MODEL_COMPARISON)
    val comparisonMode: StateFlow<ComparisonMode> = _comparisonMode.asStateFlow()

    // ========== MODEL COMPARISON MODE ==========

    // –í–æ–ø—Ä–æ—Å –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
    private val _question = MutableStateFlow("")
    val question: StateFlow<String> = _question.asStateFlow()

    // –†–µ–∂–∏–º –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è
    private val _executionMode = MutableStateFlow(ExecutionMode.PARALLEL)
    val executionMode: StateFlow<ExecutionMode> = _executionMode.asStateFlow()

    // –°–æ—Å—Ç–æ—è–Ω–∏—è –¥–ª—è –∫–∞–∂–¥–æ–π –º–æ–¥–µ–ª–∏
    private val _modelStates = MutableStateFlow<Map<String, ModelComparisonState>>(
        models.associate { it.modelId to ModelComparisonState.Idle }
    )
    val modelStates: StateFlow<Map<String, ModelComparisonState>> = _modelStates.asStateFlow()

    // –û–±—â–µ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ –∑–∞–≥—Ä—É–∑–∫–∏
    private val _isLoading = MutableStateFlow(false)
    val isLoading: StateFlow<Boolean> = _isLoading.asStateFlow()

    // ========== TOKEN ANALYSIS MODE ==========

    // –í—ã–±—Ä–∞–Ω–Ω—ã–π —Ç–∏–ø –ø—Ä–æ–º–ø—Ç–∞ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Ç–æ–∫–µ–Ω–æ–≤
    private val _selectedPromptType = MutableStateFlow(PromptType.SHORT)
    val selectedPromptType: StateFlow<PromptType> = _selectedPromptType.asStateFlow()

    // –°–æ—Å—Ç–æ—è–Ω–∏–µ –∞–Ω–∞–ª–∏–∑–∞ —Ç–æ–∫–µ–Ω–æ–≤
    private val _tokenAnalysisState = MutableStateFlow<TokenAnalysisState>(TokenAnalysisState.Idle)
    val tokenAnalysisState: StateFlow<TokenAnalysisState> = _tokenAnalysisState.asStateFlow()

    // Llama 3.2 1B –º–æ–¥–µ–ª—å –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Ç–æ–∫–µ–Ω–æ–≤ (—Ä–µ–∞–ª—å–Ω—ã–π –ª–∏–º–∏—Ç: 128K, –¥–µ–º–æ: 1024)
    private val llama32Model = models.find { it.modelId == "meta-llama/Llama-3.2-1B-Instruct:fastest" }
        ?: models.first()

    companion object {
        const val LLAMA32_CONTEXT_LIMIT = 1024  // –ò—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω–æ –æ–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏
    }

    // –ü—Ä–∏–º–µ—Ä—ã –≤–æ–ø—Ä–æ—Å–æ–≤
    val exampleQuestions = listOf(
        "–ö—Ç–æ –Ω–∞–ø–∏—Å–∞–ª —Ä–æ–º–∞–Ω '–í–æ–π–Ω–∞ –∏ –º–∏—Ä'?",
        "–ù–∞–ø–∏—à–∏ –∫–æ—Ä–æ—Ç–∫—É—é –∏—Å—Ç–æ—Ä–∏—é –ø—Ä–æ —Ä–æ–±–æ—Ç–∞",
        "–û–±—ä—è—Å–Ω–∏ —á—Ç–æ —Ç–∞–∫–æ–µ –∫–≤–∞–Ω—Ç–æ–≤–∞—è —Ñ–∏–∑–∏–∫–∞",
        "–ö–∞–∫ —Ä–∞–±–æ—Ç–∞–µ—Ç –º–∞—à–∏–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ?"
    )

    /**
     * –£—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –≤–æ–ø—Ä–æ—Å
     */
    fun setQuestion(text: String) {
        _question.value = text
    }

    /**
     * –ü–µ—Ä–µ–∫–ª—é—á–∏—Ç—å —Ä–µ–∂–∏–º –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è
     */
    fun toggleExecutionMode() {
        _executionMode.value = when (_executionMode.value) {
            ExecutionMode.PARALLEL -> ExecutionMode.SEQUENTIAL
            ExecutionMode.SEQUENTIAL -> ExecutionMode.PARALLEL
        }
    }

    /**
     * –ó–∞–ø—É—Å—Ç–∏—Ç—å —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ –¥–ª—è –æ–¥–Ω–æ–π –º–æ–¥–µ–ª–∏
     */
    fun runSingleComparison(model: HFModel) {
        if (_question.value.isBlank()) {
            updateState(model.modelId, ModelComparisonState.Error("–í–≤–µ–¥–∏—Ç–µ –≤–æ–ø—Ä–æ—Å"))
            return
        }

        viewModelScope.launch {
            try {
                updateState(model.modelId, ModelComparisonState.Loading())

                val result = comparisonService.compareModel(
                    model = model,
                    question = _question.value,
                    runs = 3,
                    onProgress = { current, total ->
                        updateState(model.modelId, ModelComparisonState.Loading(current, total))
                    }
                )

                result.fold(
                    onSuccess = { comparisonResult ->
                        updateState(model.modelId, ModelComparisonState.Success(comparisonResult))
                    },
                    onFailure = { error ->
                        updateState(model.modelId, ModelComparisonState.Error(error.message ?: "–û—à–∏–±–∫–∞"))
                    }
                )
            } catch (e: Exception) {
                updateState(model.modelId, ModelComparisonState.Error(e.message ?: "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –æ—à–∏–±–∫–∞"))
            }
        }
    }

    /**
     * –ó–∞–ø—É—Å—Ç–∏—Ç—å —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ –≤—Å–µ—Ö –º–æ–¥–µ–ª–µ–π
     */
    fun runAllComparisons() {
        if (_question.value.isBlank()) {
            models.forEach { model ->
                updateState(model.modelId, ModelComparisonState.Error("–í–≤–µ–¥–∏—Ç–µ –≤–æ–ø—Ä–æ—Å"))
            }
            return
        }

        _isLoading.value = true

        viewModelScope.launch {
            try {
                when (_executionMode.value) {
                    ExecutionMode.PARALLEL -> runParallel()
                    ExecutionMode.SEQUENTIAL -> runSequential()
                }
            } catch (e: Exception) {
                println("Error running all comparisons: ${e.message}")
            } finally {
                _isLoading.value = false
            }
        }
    }

    /**
     * –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã–π –∑–∞–ø—É—Å–∫ –≤—Å–µ—Ö —Å—Ä–∞–≤–Ω–µ–Ω–∏–π
     */
    private suspend fun runParallel() {
        // –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏–µ Loading –¥–ª—è –≤—Å–µ—Ö
        models.forEach { model ->
            updateState(model.modelId, ModelComparisonState.Loading())
        }

        // –ó–∞–ø—É—Å–∫–∞–µ–º –≤—Å–µ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ
        val jobs = models.map { model ->
            viewModelScope.async {
                val result = comparisonService.compareModel(
                    model = model,
                    question = _question.value,
                    runs = 3,
                    onProgress = { current, total ->
                        updateState(model.modelId, ModelComparisonState.Loading(current, total))
                    }
                )

                result.fold(
                    onSuccess = { comparisonResult ->
                        updateState(model.modelId, ModelComparisonState.Success(comparisonResult))
                    },
                    onFailure = { error ->
                        updateState(model.modelId, ModelComparisonState.Error(error.message ?: "–û—à–∏–±–∫–∞"))
                    }
                )
            }
        }

        jobs.awaitAll()
    }

    /**
     * –ü–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω—ã–π –∑–∞–ø—É—Å–∫ –≤—Å–µ—Ö —Å—Ä–∞–≤–Ω–µ–Ω–∏–π
     */
    private suspend fun runSequential() {
        for (model in models) {
            updateState(model.modelId, ModelComparisonState.Loading())

            val result = comparisonService.compareModel(
                model = model,
                question = _question.value,
                runs = 3,
                onProgress = { current, total ->
                    updateState(model.modelId, ModelComparisonState.Loading(current, total))
                }
            )

            result.fold(
                onSuccess = { comparisonResult ->
                    updateState(model.modelId, ModelComparisonState.Success(comparisonResult))
                },
                onFailure = { error ->
                    updateState(model.modelId, ModelComparisonState.Error(error.message ?: "–û—à–∏–±–∫–∞"))
                }
            )
        }
    }

    /**
     * –û—á–∏—Å—Ç–∏—Ç—å –≤—Å–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
     */
    fun clearResults() {
        _modelStates.value = models.associate { it.modelId to ModelComparisonState.Idle }
        _isLoading.value = false
    }

    /**
     * –£—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –ø—Ä–∏–º–µ—Ä –≤–æ–ø—Ä–æ—Å–∞
     */
    fun setExampleQuestion(index: Int) {
        if (index in exampleQuestions.indices) {
            _question.value = exampleQuestions[index]
        }
    }

    /**
     * –§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —á–∏—Å–µ–ª –¥–ª—è –æ—Ç—á–µ—Ç–∞
     */
    private fun formatDouble(value: Double, decimals: Int = 2): String {
        val multiplier = when (decimals) {
            0 -> 1.0
            1 -> 10.0
            2 -> 100.0
            else -> 100.0
        }
        val rounded = (value * multiplier).toInt() / multiplier
        return rounded.toString()
    }

    /**
     * –ü–æ–≤—Ç–æ—Ä–∏—Ç—å —Å—Ç—Ä–æ–∫—É N —Ä–∞–∑
     */
    private fun repeatString(str: String, count: Int): String {
        return buildString {
            repeat(count) {
                append(str)
            }
        }
    }

    /**
     * –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å —Ç–µ–∫—Å—Ç–æ–≤—ã–π –æ—Ç—á–µ—Ç –¥–ª—è —ç–∫—Å–ø–æ—Ä—Ç–∞
     */
    fun generateReport(): String {
        val results = _modelStates.value.values
            .filterIsInstance<ModelComparisonState.Success>()
            .map { it.result }
            .sortedBy { it.model.displayName }

        if (results.isEmpty()) {
            return "–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —ç–∫—Å–ø–æ—Ä—Ç–∞. –ó–∞–ø—É—Å—Ç–∏—Ç–µ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π."
        }

        val winners = comparisonService.determineWinners(results)

        val report = buildString {
            appendLine(repeatString("=", 80))
            appendLine("–û–¢–ß–ï–¢: –°–†–ê–í–ù–ï–ù–ò–ï –ú–û–î–ï–õ–ï–ô HUGGINGFACE")
            appendLine(repeatString("=", 80))
            appendLine()
            appendLine("–í–æ–ø—Ä–æ—Å: ${_question.value}")
            appendLine("–î–∞—Ç–∞: ${getCurrentTimestamp()}")
            appendLine("–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –≥–µ–Ω–µ—Ä–∞—Ü–∏–π –Ω–∞ –º–æ–¥–µ–ª—å: 3")
            appendLine("–†–µ–∂–∏–º –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è: ${_executionMode.value}")
            appendLine()
            appendLine(repeatString("=", 80))
            appendLine("–ü–û–ë–ï–î–ò–¢–ï–õ–ò –í –ö–ê–¢–ï–ì–û–†–ò–Ø–•")
            appendLine(repeatString("=", 80))
            appendLine("  üèÉ –°–∞–º–∞—è –±—ã—Å—Ç—Ä–∞—è: ${winners.fastest}")
            appendLine("  üéØ –°–∞–º–∞—è –∫–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω–∞—è: ${winners.mostConsistent}")
            appendLine("  üé® –°–∞–º–∞—è –∫—Ä–µ–∞—Ç–∏–≤–Ω–∞—è: ${winners.mostCreative}")
            appendLine("  üìù –°–∞–º—ã–µ –¥–ª–∏–Ω–Ω—ã–µ –æ—Ç–≤–µ—Ç—ã: ${winners.longestResponses}")
            appendLine("  ‚ö° –°–∞–º–∞—è —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–∞—è: ${winners.mostEfficient}")
            appendLine()
            appendLine(repeatString("=", 80))
            appendLine("–°–†–ê–í–ù–ò–¢–ï–õ–¨–ù–ê–Ø –¢–ê–ë–õ–ò–¶–ê –ú–ï–¢–†–ò–ö")
            appendLine(repeatString("=", 80))
            appendLine()

            // –ó–∞–≥–æ–ª–æ–≤–æ–∫ —Ç–∞–±–ª–∏—Ü—ã
            append("–ú–µ—Ç—Ä–∏–∫–∞".padEnd(25))
            results.forEach { result ->
                append(result.model.displayName.take(15).padStart(15))
            }
            appendLine()
            appendLine(repeatString("-", 80))

            // –°—Ç—Ä–æ–∫–∏ –º–µ—Ç—Ä–∏–∫
            append("–í—Ä–µ–º—è (–º—Å)".padEnd(25))
            results.forEach { result ->
                append(formatDouble(result.metrics.avgResponseTime, 0).padStart(15))
            }
            appendLine()

            append("–¢–æ–∫–µ–Ω—ã (–≤—Å–µ–≥–æ)".padEnd(25))
            results.forEach { result ->
                append(formatDouble(result.metrics.avgTotalTokens, 0).padStart(15))
            }
            appendLine()

            append("Self-BLEU".padEnd(25))
            results.forEach { result ->
                append(formatDouble(result.metrics.selfBleu, 2).padStart(15))
            }
            appendLine()

            append("–°–æ–≥–ª–∞—Å–æ–≤–∞–Ω–Ω–æ—Å—Ç—å".padEnd(25))
            results.forEach { result ->
                append(formatDouble(result.metrics.semanticConsistency, 2).padStart(15))
            }
            appendLine()

            append("–°–ª–æ–≤ (—Å—Ä–µ–¥–Ω–µ–µ)".padEnd(25))
            results.forEach { result ->
                append(formatDouble(result.metrics.avgWordCount, 0).padStart(15))
            }
            appendLine()

            append("–£–Ω–∏–∫. —Å–ª–æ–≤".padEnd(25))
            results.forEach { result ->
                append(formatDouble(result.metrics.avgUniqueWords, 0).padStart(15))
            }
            appendLine()
            appendLine()

            // –î–µ—Ç–∞–ª—å–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –¥–ª—è –∫–∞–∂–¥–æ–π –º–æ–¥–µ–ª–∏
            results.forEach { result ->
                appendLine()
                appendLine(repeatString("=", 80))
                appendLine("–ú–û–î–ï–õ–¨: ${result.model.displayName}")
                appendLine("ID: ${result.model.modelId}")
                appendLine(repeatString("=", 80))
                appendLine()

                // –ú–µ—Ç—Ä–∏–∫–∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
                appendLine("–ü–†–û–ò–ó–í–û–î–ò–¢–ï–õ–¨–ù–û–°–¢–¨:")
                appendLine("  –°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è: ${formatDouble(result.metrics.avgResponseTime, 0)} –º—Å")
                appendLine("  –ú–∏–Ω –≤—Ä–µ–º—è: ${result.metrics.minResponseTime} –º—Å")
                appendLine("  –ú–∞–∫—Å –≤—Ä–µ–º—è: ${result.metrics.maxResponseTime} –º—Å")
                appendLine()

                // –ú–µ—Ç—Ä–∏–∫–∏ —Ç–æ–∫–µ–Ω–æ–≤
                appendLine("–¢–û–ö–ï–ù–´:")
                appendLine("  –í—Ö–æ–¥ (—Å—Ä–µ–¥–Ω–µ–µ): ${formatDouble(result.metrics.avgInputTokens, 0)}")
                appendLine("  –í—ã—Ö–æ–¥ (—Å—Ä–µ–¥–Ω–µ–µ): ${formatDouble(result.metrics.avgOutputTokens, 0)}")
                appendLine("  –í—Å–µ–≥–æ (—Å—Ä–µ–¥–Ω–µ–µ): ${formatDouble(result.metrics.avgTotalTokens, 0)}")
                appendLine()

                // –ú–µ—Ç—Ä–∏–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞
                appendLine("–ö–ê–ß–ï–°–¢–í–û:")
                appendLine("  Self-BLEU: ${formatDouble(result.metrics.selfBleu, 2)}")
                appendLine("  –°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∞—è —Å–æ–≥–ª–∞—Å–æ–≤–∞–Ω–Ω–æ—Å—Ç—å: ${formatDouble(result.metrics.semanticConsistency, 2)}")
                appendLine("  –°–ª–æ–≤ (—Å—Ä–µ–¥–Ω–µ–µ): ${formatDouble(result.metrics.avgWordCount, 0)}")
                appendLine("  –°–∏–º–≤–æ–ª–æ–≤ (—Å—Ä–µ–¥–Ω–µ–µ): ${formatDouble(result.metrics.avgCharCount, 0)}")
                appendLine("  –£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Å–ª–æ–≤: ${formatDouble(result.metrics.avgUniqueWords, 0)}")
                appendLine("  –°—Ç—Ä—É–∫—Ç—É—Ä–Ω–æ–µ —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏–µ: ${formatDouble(result.metrics.responseVariability.structuralDiversity, 2)}")
                appendLine()

                // –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
                val recommendation = comparisonService.generateRecommendation(result)
                appendLine("–†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò:")
                appendLine(recommendation.summary)
                appendLine()
                appendLine("–°–∏–ª—å–Ω—ã–µ —Å—Ç–æ—Ä–æ–Ω—ã:")
                recommendation.strengths.forEach { appendLine("  ‚úì $it") }
                appendLine()
                appendLine("–°–ª–∞–±—ã–µ —Å—Ç–æ—Ä–æ–Ω—ã:")
                recommendation.weaknesses.forEach { appendLine("  ‚úó $it") }
                appendLine()
                appendLine("–õ—É—á—à–∏–µ —Å—Ü–µ–Ω–∞—Ä–∏–∏:")
                recommendation.bestUseCases.forEach { appendLine("  ‚Ä¢ $it") }
                appendLine()

                // –ü—Ä–∏–º–µ—Ä—ã –æ—Ç–≤–µ—Ç–æ–≤
                appendLine("–ü–†–ò–ú–ï–†–´ –û–¢–í–ï–¢–û–í:")
                result.responses.forEachIndexed { index, response ->
                    appendLine()
                    appendLine("--- –û—Ç–≤–µ—Ç ${index + 1} (${result.executionTimes.getOrNull(index) ?: 0}–º—Å) ---")
                    appendLine(response) // –ü–æ–ª–Ω—ã–π —Ç–µ–∫—Å—Ç –æ—Ç–≤–µ—Ç–∞
                    appendLine()
                }

                // –û—à–∏–±–∫–∏ (–µ—Å–ª–∏ –µ—Å—Ç—å)
                if (result.errors.isNotEmpty()) {
                    appendLine("–û–®–ò–ë–ö–ò:")
                    result.errors.forEach { appendLine("  ‚ùå $it") }
                    appendLine()
                }
            }

            appendLine()
            appendLine(repeatString("=", 80))
            appendLine("–ö–û–ù–ï–¶ –û–¢–ß–ï–¢–ê")
            appendLine(repeatString("=", 80))
        }

        return report
    }

    /**
     * –û–±–Ω–æ–≤–∏—Ç—å —Å–æ—Å—Ç–æ—è–Ω–∏–µ –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π –º–æ–¥–µ–ª–∏
     */
    private fun updateState(modelId: String, state: ModelComparisonState) {
        _modelStates.value = _modelStates.value.toMutableMap().apply {
            put(modelId, state)
        }
    }

    // ========== TOKEN ANALYSIS FUNCTIONS ==========

    /**
     * –ü–µ—Ä–µ–∫–ª—é—á–∏—Ç—å —Ä–µ–∂–∏–º —Ä–∞–±–æ—Ç—ã —ç–∫—Ä–∞–Ω–∞
     */
    fun toggleComparisonMode() {
        _comparisonMode.value = when (_comparisonMode.value) {
            ComparisonMode.MODEL_COMPARISON -> ComparisonMode.TOKEN_ANALYSIS
            ComparisonMode.TOKEN_ANALYSIS -> ComparisonMode.MODEL_COMPARISON
        }
    }

    /**
     * –£—Å—Ç–∞–Ω–æ–≤–∏—Ç—å —Ç–∏–ø –ø—Ä–æ–º–ø—Ç–∞ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
     */
    fun setPromptType(type: PromptType) {
        _selectedPromptType.value = type
    }

    /**
     * –ó–∞–ø—É—Å—Ç–∏—Ç—å –∞–Ω–∞–ª–∏–∑ —Ç–æ–∫–µ–Ω–æ–≤ –¥–ª—è –≤—Å–µ—Ö —Ç–∏–ø–æ–≤ –ø—Ä–æ–º–ø—Ç–æ–≤
     */
    fun runTokenAnalysis() {
        viewModelScope.launch {
            try {
                _tokenAnalysisState.value = TokenAnalysisState.Loading(null, 0, 4)

                val results = mutableListOf<TokenTestResult>()
                val promptTypes = listOf(
                    PromptType.SHORT,
                    PromptType.MEDIUM,
                    PromptType.LONG,
                    PromptType.EXCEEDS_LIMIT
                )

                promptTypes.forEachIndexed { index, promptType ->
                    _tokenAnalysisState.value = TokenAnalysisState.Loading(
                        currentTest = promptType,
                        completedTests = index,
                        totalTests = promptTypes.size
                    )

                    val result = runSingleTokenTest(promptType)
                    results.add(result)
                }

                _tokenAnalysisState.value = TokenAnalysisState.Success(results)
            } catch (e: Exception) {
                _tokenAnalysisState.value = TokenAnalysisState.Error(
                    e.message ?: "–û—à–∏–±–∫–∞ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ —Ç–æ–∫–µ–Ω–æ–≤"
                )
            }
        }
    }

    /**
     * –ó–∞–ø—É—Å—Ç–∏—Ç—å —Ç–µ—Å—Ç –¥–ª—è –æ–¥–Ω–æ–≥–æ —Ç–∏–ø–∞ –ø—Ä–æ–º–ø—Ç–∞
     */
    private suspend fun runSingleTokenTest(promptType: PromptType): TokenTestResult {
        val prompt = TokenTestPrompts.getPromptByType(promptType)
        val estimatedTokens = estimateTokens(prompt)

        return try {
            val startTime = System.currentTimeMillis()

            val result = hfService.generateText(
                modelId = llama32Model.modelId,
                prompt = prompt,
                maxTokens = 500,
                temperature = 0.7
            )

            val endTime = System.currentTimeMillis()
            val executionTime = endTime - startTime

            when {
                result.isSuccess -> {
                    val response = result.getOrThrow()
                    val totalTokens = response.tokenUsage.totalTokens
                    val percentageUsed = (totalTokens.toDouble() / LLAMA32_CONTEXT_LIMIT) * 100

                    TokenTestResult(
                        promptType = promptType.name,
                        prompt = prompt,
                        promptLength = prompt.length,
                        estimatedPromptTokens = estimatedTokens,
                        actualInputTokens = response.tokenUsage.promptTokens,
                        actualOutputTokens = response.tokenUsage.completionTokens,
                        totalTokens = totalTokens,
                        modelContextLimit = LLAMA32_CONTEXT_LIMIT,
                        percentageUsed = percentageUsed,
                        success = true,
                        response = response.generatedText,
                        executionTime = executionTime,
                        requestedModel = llama32Model.modelId,
                        actualModelUsed = response.actualModelUsed
                    )
                }
                result.isFailure -> {
                    val error = result.exceptionOrNull()
                    TokenTestResult(
                        promptType = promptType.name,
                        prompt = prompt,
                        promptLength = prompt.length,
                        estimatedPromptTokens = estimatedTokens,
                        actualInputTokens = 0,
                        actualOutputTokens = 0,
                        totalTokens = 0,
                        modelContextLimit = LLAMA32_CONTEXT_LIMIT,
                        percentageUsed = 0.0,
                        success = false,
                        error = error?.message ?: "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –æ—à–∏–±–∫–∞",
                        executionTime = executionTime,
                        requestedModel = llama32Model.modelId
                    )
                }
                else -> {
                    TokenTestResult(
                        promptType = promptType.name,
                        prompt = prompt,
                        promptLength = prompt.length,
                        estimatedPromptTokens = estimatedTokens,
                        actualInputTokens = 0,
                        actualOutputTokens = 0,
                        totalTokens = 0,
                        modelContextLimit = LLAMA32_CONTEXT_LIMIT,
                        percentageUsed = 0.0,
                        success = false,
                        error = "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –æ—à–∏–±–∫–∞",
                        requestedModel = llama32Model.modelId
                    )
                }
            }
        } catch (e: Exception) {
            TokenTestResult(
                promptType = promptType.name,
                prompt = prompt,
                promptLength = prompt.length,
                estimatedPromptTokens = estimatedTokens,
                actualInputTokens = 0,
                actualOutputTokens = 0,
                totalTokens = 0,
                modelContextLimit = LLAMA32_CONTEXT_LIMIT,
                percentageUsed = 0.0,
                success = false,
                error = e.message ?: "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –æ—à–∏–±–∫–∞",
                requestedModel = llama32Model.modelId
            )
        }
    }

    /**
     * –ü—Ä–∏–º–µ—Ä–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —Ç–æ–∫–µ–Ω–æ–≤ –≤ —Ç–µ–∫—Å—Ç–µ
     * –î–ª—è —Ä—É—Å—Å–∫–æ–≥–æ —Ç–µ–∫—Å—Ç–∞: ~1.3 —Ç–æ–∫–µ–Ω–∞ –Ω–∞ —Å–ª–æ–≤–æ
     */
    private fun estimateTokens(text: String): Int {
        val wordCount = text.split(Regex("\\s+")).size
        return (wordCount * 1.3).toInt()
    }

    /**
     * –û—á–∏—Å—Ç–∏—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞–Ω–∞–ª–∏–∑–∞ —Ç–æ–∫–µ–Ω–æ–≤
     */
    fun clearTokenAnalysis() {
        _tokenAnalysisState.value = TokenAnalysisState.Idle
    }

    /**
     * –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –æ—Ç—á–µ—Ç –ø–æ –∞–Ω–∞–ª–∏–∑—É —Ç–æ–∫–µ–Ω–æ–≤
     */
    fun generateTokenAnalysisReport(): String {
        val state = _tokenAnalysisState.value
        if (state !is TokenAnalysisState.Success) {
            return "–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —ç–∫—Å–ø–æ—Ä—Ç–∞. –ó–∞–ø—É—Å—Ç–∏—Ç–µ –∞–Ω–∞–ª–∏–∑ —Ç–æ–∫–µ–Ω–æ–≤."
        }

        val results = state.results

        return buildString {
            appendLine(repeatString("=", 80))
            appendLine("–û–¢–ß–ï–¢: –ê–ù–ê–õ–ò–ó –¢–û–ö–ï–ù–û–í (${llama32Model.displayName.uppercase()})")
            appendLine(repeatString("=", 80))
            appendLine()
            appendLine("–ú–æ–¥–µ–ª—å: ${llama32Model.displayName}")
            appendLine("ID –º–æ–¥–µ–ª–∏: ${llama32Model.modelId}")
            appendLine("–õ–∏–º–∏—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞: $LLAMA32_CONTEXT_LIMIT —Ç–æ–∫–µ–Ω–æ–≤")
            appendLine("–î–∞—Ç–∞: ${getCurrentTimestamp()}")
            appendLine()
            appendLine(repeatString("=", 80))
            appendLine("–°–†–ê–í–ù–ò–¢–ï–õ–¨–ù–ê–Ø –¢–ê–ë–õ–ò–¶–ê –¢–û–ö–ï–ù–û–í")
            appendLine(repeatString("=", 80))
            appendLine()

            // –ó–∞–≥–æ–ª–æ–≤–æ–∫
            append("–¢–∏–ø –ø—Ä–æ–º–ø—Ç–∞".padEnd(20))
            append("Input".padStart(10))
            append("Output".padStart(10))
            append("Total".padStart(10))
            append("% –ª–∏–º–∏—Ç–∞".padStart(12))
            append("–°—Ç–∞—Ç—É—Å".padStart(10))
            appendLine()
            appendLine(repeatString("-", 80))

            // –°—Ç—Ä–æ–∫–∏ –¥–∞–Ω–Ω—ã—Ö
            results.forEach { result ->
                val promptTypeDisplay = when (result.promptType) {
                    "SHORT" -> "–ö–æ—Ä–æ—Ç–∫–∏–π"
                    "MEDIUM" -> "–°—Ä–µ–¥–Ω–∏–π"
                    "LONG" -> "–î–ª–∏–Ω–Ω—ã–π"
                    "EXCEEDS_LIMIT" -> "–ü—Ä–µ–≤—ã—à–∞–µ—Ç –ª–∏–º–∏—Ç"
                    else -> result.promptType
                }

                val status = when {
                    !result.success -> "‚ùå –û—à–∏–±–∫–∞"
                    result.percentageUsed > 90 -> "üî¥ >90%"
                    result.percentageUsed > 70 -> "üü° >70%"
                    else -> "‚úÖ OK"
                }

                append(promptTypeDisplay.padEnd(20))
                append(result.actualInputTokens.toString().padStart(10))
                append(result.actualOutputTokens.toString().padStart(10))
                append(result.totalTokens.toString().padStart(10))
                append(formatDouble(result.percentageUsed, 1).padStart(12))
                append(status.padStart(10))
                appendLine()
            }

            appendLine()
            appendLine(repeatString("=", 80))
            appendLine("–î–ï–¢–ê–õ–¨–ù–´–ï –†–ï–ó–£–õ–¨–¢–ê–¢–´")
            appendLine(repeatString("=", 80))

            results.forEach { result ->
                appendLine()
                appendLine("--- ${result.promptType} ---")
                appendLine("–î–ª–∏–Ω–∞ –ø—Ä–æ–º–ø—Ç–∞: ${result.promptLength} —Å–∏–º–≤–æ–ª–æ–≤")
                appendLine("–û—Ü–µ–Ω–∫–∞ —Ç–æ–∫–µ–Ω–æ–≤: ~${result.estimatedPromptTokens} —Ç–æ–∫–µ–Ω–æ–≤")
                appendLine("–†–µ–∞–ª—å–Ω—ã–µ —Ç–æ–∫–µ–Ω—ã: ${result.actualInputTokens} (–≤—Ö–æ–¥) + ${result.actualOutputTokens} (–≤—ã—Ö–æ–¥) = ${result.totalTokens}")
                appendLine("–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞: ${formatDouble(result.percentageUsed, 2)}% –∏–∑ $LLAMA32_CONTEXT_LIMIT")
                appendLine("–í—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è: ${result.executionTime} –º—Å")
                appendLine()

                // –ü–æ–ª–Ω—ã–π —Ç–µ–∫—Å—Ç –ø—Ä–æ–º–ø—Ç–∞
                appendLine("–ü—Ä–æ–º–ø—Ç:")
                appendLine(repeatString("-", 80))
                appendLine(result.prompt)
                appendLine(repeatString("-", 80))
                appendLine()

                if (result.success) {
                    appendLine("–°—Ç–∞—Ç—É—Å: ‚úÖ –£—Å–ø–µ—à–Ω–æ")
                    appendLine()
                    appendLine("–û—Ç–≤–µ—Ç –º–æ–¥–µ–ª–∏:")
                    appendLine(repeatString("-", 80))
                    appendLine(result.response) // –ü–æ–ª–Ω—ã–π —Ç–µ–∫—Å—Ç –æ—Ç–≤–µ—Ç–∞
                    appendLine(repeatString("-", 80))
                } else {
                    appendLine("–°—Ç–∞—Ç—É—Å: ‚ùå –û—à–∏–±–∫–∞")
                    appendLine("–û—à–∏–±–∫–∞: ${result.error}")
                }
                appendLine()
            }

            appendLine(repeatString("=", 80))
            appendLine("–ö–û–ù–ï–¶ –û–¢–ß–ï–¢–ê")
            appendLine(repeatString("=", 80))
        }
    }

    override fun onCleared() {
        super.onCleared()
        comparisonService.close()
    }
}
